{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import smote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the data into dataframe\n",
    "car_df = pd.read_csv('newCardata.csv')\n",
    "car_features = pd.read_csv('finalDataPreprocessBinary.csv')\n",
    "car_label = car_df['FraudFound']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15419,)\n"
     ]
    }
   ],
   "source": [
    "#change the label of the data\n",
    "labelNo = LabelEncoder()\n",
    "car_df['FraudFound'] = labelNo.fit_transform(car_df['FraudFound'].astype('str'))\n",
    "car_label = car_df['FraudFound']\n",
    "print(car_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15419, 52) (15419,)\n",
      "xtrain: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#split the data into train and test\n",
    "print(car_features.shape,car_label.shape)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(car_features,car_label,random_state=3,test_size=0.25)\n",
    "print('xtrain:',type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model object\n",
    "model = RandomForestClassifier(n_estimators=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier:\n",
      "<class 'numpy.ndarray'> (3855,) [0 0 0 ..., 0 0 0]\n",
      "Accuracy is  93.64\n"
     ]
    }
   ],
   "source": [
    "print('Random forest classifier:')\n",
    "predicted = model.predict(X_test)\n",
    "print(type(predicted),predicted.shape,predicted)\n",
    "print('Accuracy is ',round(accuracy_score(y_test,model.predict(X_test)) * 100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3607    2]\n",
      " [ 243    3]]\n"
     ]
    }
   ],
   "source": [
    "# calculating specifity and sensitivity\n",
    "# 0  := Negative\n",
    "# 1 := Positive\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "print(\"Confusion Matrix:\\n\",cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 3607\n",
      "FP: 2\n",
      "FN: 243\n",
      "TP: 3\n",
      "Accuracy: 93.64461738\n",
      "Sensitivity: 1.21951219512\n",
      "Specificity: 99.944582987\n"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = cm.ravel()\n",
    "print(\"TN:\",TN)\n",
    "print(\"FP:\",FP)\n",
    "print(\"FN:\",FN)\n",
    "print(\"TP:\",TP)\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'>\n",
      "3855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#converting pandas.core.series.Series to numpy.ndarray\n",
    "print(type(y_test),type(predicted))\n",
    "ytest = pd.Series(y_test).values\n",
    "print((ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of fraud cases: 246\n",
      "No of fauld cases predicted by model: 5\n",
      "No of fraud correctly predicted  as fault: 3\n"
     ]
    }
   ],
   "source": [
    "#find the index where both are 1.\n",
    "count = 0\n",
    "fault = 0\n",
    "predictedfault = 0\n",
    "for i in range(predicted.shape[0]):\n",
    "    if((predicted[i] == 1) and (ytest[i] == 1)):\n",
    "        count += 1\n",
    "    if(ytest[i] == 1):\n",
    "        fault += 1\n",
    "    if(predicted[i]==1):\n",
    "        predictedfault += 1\n",
    "print(\"No of fraud cases:\",fault)\n",
    "print(\"No of fauld cases predicted by model:\",predictedfault)\n",
    "print(\"No of fraud correctly predicted  as fault:\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with Adabost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  92.68\n"
     ]
    }
   ],
   "source": [
    "#model object\n",
    "X_train,X_test,y_train,y_test = train_test_split(car_features,car_label,random_state=43,test_size=0.25)\n",
    "def adaboost(X_train, X_test, y_train):\n",
    "    model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test) \n",
    "    return y_pred\n",
    "\n",
    "# AdaBoost\n",
    "y_baseline = adaboost(X_train, X_test, y_train)\n",
    "print('Accuracy is ',round(accuracy_score(y_test,y_baseline) * 100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3571   22]\n",
      " [ 260    2]]\n",
      "Accuracy: 92.6848249027\n",
      "Sensitivity: 0.763358778626\n",
      "Specificity: 99.3876983023\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,y_baseline)\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3855\n",
      "3855\n",
      "[0 0 0 ..., 0 0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#converting pandas.core.series.Series to numpy.ndarray\n",
    "ytest = pd.Series(y_test).values\n",
    "print((ytest.shape[0]))\n",
    "print(predicted.shape[0])\n",
    "print(ytest)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of fraud cases: 262\n",
      "No of fauld cases predicted by model: 5\n",
      "No of fraud correctly predicted  as fault: 0\n"
     ]
    }
   ],
   "source": [
    "#find the index where both are 1.\n",
    "count = 0\n",
    "fault = 0\n",
    "predictedfault = 0\n",
    "for i in range(predicted.shape[0]):\n",
    "    \n",
    "    if((predicted[i] == 1) and (ytest[i] == 1)):\n",
    "        count += 1\n",
    "    if(ytest[i] == 1):\n",
    "        fault += 1\n",
    "    if(predicted[i]==1):\n",
    "        predictedfault += 1\n",
    "print(\"No of fraud cases:\",fault)\n",
    "print(\"No of fauld cases predicted by model:\",predictedfault)\n",
    "print(\"No of fraud correctly predicted  as fault:\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  88.17\n",
      "Confusion Matrix:\n",
      " [[3571   22]\n",
      " [ 260    2]]\n",
      "Accuracy: 92.6848249027\n",
      "Sensitivity: 0.763358778626\n",
      "Specificity: 99.3876983023\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.93      0.94      3593\n",
      "          1       0.17      0.20      0.19       262\n",
      "\n",
      "avg / total       0.89      0.88      0.89      3855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adabost after SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_sample(X_train, y_train)\n",
    "y_smote = adaboost(X_train_sm, X_test, y_train_sm)\n",
    "target_names = ['0', '1']\n",
    "\n",
    "#predict accuracy\n",
    "print('Accuracy is ',round(accuracy_score(y_test,y_smote) * 100,2))\n",
    "cm = confusion_matrix(y_test,y_baseline)\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)\n",
    "print(classification_report(y_test, y_smote,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  88.17\n",
      "Confusion Matrix:\n",
      " [[3571   22]\n",
      " [ 260    2]]\n",
      "Accuracy: 92.6848249027\n",
      "Sensitivity: 0.763358778626\n",
      "Specificity: 99.3876983023\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.65      0.78      3593\n",
      "          1       0.14      0.78      0.23       262\n",
      "\n",
      "avg / total       0.92      0.65      0.74      3855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random underSampling(RUS)\n",
    "from sklearn.utils import resample\n",
    "X_full = X_train.copy()\n",
    "X_full['target'] = y_train\n",
    "X_maj = X_full[X_full.target==0]\n",
    "X_min = X_full[X_full.target==1]\n",
    "X_maj_rus = resample(X_maj,replace=False,n_samples=len(X_min),random_state=44)\n",
    "X_rus = pd.concat([X_maj_rus, X_min])\n",
    "X_train_rus = X_rus.drop(['target'], axis=1)\n",
    "y_train_rus = X_rus.target\n",
    "y_rus = adaboost(X_train_rus, X_test, y_train_rus)\n",
    "\n",
    "#predict accuracy\n",
    "#predict accuracy\n",
    "print('Accuracy is ',round(accuracy_score(y_test,y_smote) * 100,2))\n",
    "cm = confusion_matrix(y_test,y_baseline)\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)\n",
    "\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test, y_rus,target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'imblearn.over_sampling.smote' has no attribute 'SMOTEBoost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1aba77231f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m for algorithm in [smote.SMOTEBoost(n_estimators=100, n_samples=300),\n\u001b[0m\u001b[1;32m      5\u001b[0m                   rus.RUSBoost(n_estimators=100, n_samples=300)]:\n\u001b[1;32m      6\u001b[0m     \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'imblearn.over_sampling.smote' has no attribute 'SMOTEBoost'"
     ]
    }
   ],
   "source": [
    "#SMOTEAdaBoost and RUS Bost\n",
    "\n",
    "\n",
    "for algorithm in [smote.SMOTEBoost(n_estimators=100, n_samples=300)]:\n",
    "    algorithm.fit(X_train, y_train)\n",
    "    y_pred = algorithm.predict(X_test)\n",
    "    print()\n",
    "    print(str(algorithm))\n",
    "    print()\n",
    "    print(classification_report(y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.97006233744130022, 0.9685430463576159, 0.96851786252311811, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision_recall_fscore_support(y_test, predicted, average='micro')\n",
    "precision_recall_fscore_support(y_test, predicted, average='macro')\n",
    "precision_recall_fscore_support(y_test, predicted, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

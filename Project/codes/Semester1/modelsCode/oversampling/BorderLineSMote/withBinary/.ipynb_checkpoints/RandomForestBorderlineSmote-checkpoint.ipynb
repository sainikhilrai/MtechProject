{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the data into dataframe\n",
    "car_df = pd.read_csv('newCardata.csv')\n",
    "car_features = pd.read_csv('finalDataPreprocessBinary.csv')\n",
    "car_label = car_df['FraudFound']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15419,)\n"
     ]
    }
   ],
   "source": [
    "#change the label of the data\n",
    "labelNo = LabelEncoder()\n",
    "car_df['FraudFound'] = labelNo.fit_transform(car_df['FraudFound'].astype('str'))\n",
    "car_label = car_df['FraudFound']\n",
    "print(car_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15419, 52) (15419,)\n",
      "xtrain: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#split the data into train and test\n",
    "print(car_features.shape,car_label.shape)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(car_features,car_label,random_state=3,test_size=0.25)\n",
    "print('xtrain:',type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model object\n",
    "model = RandomForestClassifier(n_estimators=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier:\n",
      "<class 'numpy.ndarray'> (3855,) [0 0 0 ..., 0 0 0]\n",
      "Accuracy is  93.7\n"
     ]
    }
   ],
   "source": [
    "print('Random forest classifier:')\n",
    "predicted = model.predict(X_test)\n",
    "print(type(predicted),predicted.shape,predicted)\n",
    "print('Accuracy is ',round(accuracy_score(y_test,model.predict(X_test)) * 100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3607    2]\n",
      " [ 241    5]]\n"
     ]
    }
   ],
   "source": [
    "# calculating specifity and sensitivity\n",
    "# 0  := Negative\n",
    "# 1 := Positive\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "print(\"Confusion Matrix:\\n\",cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 3607\n",
      "FP: 2\n",
      "FN: 241\n",
      "TP: 5\n",
      "Accuracy: 93.6964980545\n",
      "Sensitivity: 2.0325203252\n",
      "Specificity: 99.944582987\n"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = cm.ravel()\n",
    "print(\"TN:\",TN)\n",
    "print(\"FP:\",FP)\n",
    "print(\"FN:\",FN)\n",
    "print(\"TP:\",TP)\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'>\n",
      "3855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#converting pandas.core.series.Series to numpy.ndarray\n",
    "print(type(y_test),type(predicted))\n",
    "ytest = pd.Series(y_test).values\n",
    "print((ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of fraud cases: 246\n",
      "No of fauld cases predicted by model: 7\n",
      "No of fraud correctly predicted  as fault: 5\n"
     ]
    }
   ],
   "source": [
    "#find the index where both are 1.\n",
    "count = 0\n",
    "fault = 0\n",
    "predictedfault = 0\n",
    "for i in range(predicted.shape[0]):\n",
    "    if((predicted[i] == 1) and (ytest[i] == 1)):\n",
    "        count += 1\n",
    "    if(ytest[i] == 1):\n",
    "        fault += 1\n",
    "    if(predicted[i]==1):\n",
    "        predictedfault += 1\n",
    "print(\"No of fraud cases:\",fault)\n",
    "print(\"No of fauld cases predicted by model:\",predictedfault)\n",
    "print(\"No of fraud correctly predicted  as fault:\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28992, 52) (28992,)\n"
     ]
    }
   ],
   "source": [
    "#with Smote\n",
    "sm = SMOTE()\n",
    "features,labels = sm.fit_sample(car_features,car_label)\n",
    "print(features.shape,labels.shape)\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,labels,random_state=3,test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model object\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier:\n",
      "<class 'numpy.ndarray'> (7248,) [1 1 0 ..., 0 0 1]\n",
      "Accuracy is  96.85\n"
     ]
    }
   ],
   "source": [
    "print('Random forest classifier:')\n",
    "predicted = model.predict(X_test)\n",
    "print(type(predicted),predicted.shape,predicted)\n",
    "print('Accuracy is ',round(accuracy_score(y_test,model.predict(X_test)) * 100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3612   11]\n",
      " [ 217 3408]]\n",
      "Accuracy: 96.8543046358\n",
      "Sensitivity: 94.0137931034\n",
      "Specificity: 99.696384212\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,predicted)\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7248\n",
      "7248\n",
      "[1 1 0 ..., 0 0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#converting pandas.core.series.Series to numpy.ndarray\n",
    "ytest = pd.Series(y_test).values\n",
    "print((ytest.shape[0]))\n",
    "print(predicted.shape[0])\n",
    "print(ytest)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of fraud cases: 3625\n",
      "No of fauld cases predicted by model: 3419\n",
      "No of fraud correctly predicted  as fault: 3408\n"
     ]
    }
   ],
   "source": [
    "#find the index where both are 1.\n",
    "count = 0\n",
    "fault = 0\n",
    "predictedfault = 0\n",
    "for i in range(predicted.shape[0]):\n",
    "    \n",
    "    if((predicted[i] == 1) and (ytest[i] == 1)):\n",
    "        count += 1\n",
    "    if(ytest[i] == 1):\n",
    "        fault += 1\n",
    "    if(predicted[i]==1):\n",
    "        predictedfault += 1\n",
    "print(\"No of fraud cases:\",fault)\n",
    "print(\"No of fauld cases predicted by model:\",predictedfault)\n",
    "print(\"No of fraud correctly predicted  as fault:\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.97006233744130022, 0.9685430463576159, 0.96851786252311811, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision_recall_fscore_support(y_test, predicted, average='micro')\n",
    "precision_recall_fscore_support(y_test, predicted, average='macro')\n",
    "precision_recall_fscore_support(y_test, predicted, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.5/site-packages/sklearn/utils/fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import math\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15419, 97)\n"
     ]
    }
   ],
   "source": [
    "#Read the data into dataframe\n",
    "car_df = pd.read_csv('newCardata.csv')\n",
    "car_features = pd.read_csv('finalDataPreprocess.csv')\n",
    "\n",
    "#encode the label as 1's or 0's\n",
    "label_Number = LabelEncoder()\n",
    "car_df['FraudFound'] = label_Number.fit_transform(car_df['FraudFound'].astype('str'))\n",
    "car_label = car_df['FraudFound']\n",
    "print(car_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11564, 97) (3855, 97)\n"
     ]
    }
   ],
   "source": [
    "#divide the data into train and test set\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(car_features,car_label,random_state=3,test_size=0.25)\n",
    "print(X_train.shape,X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3605    4]\n",
      " [ 242    4]]\n",
      "TN: 3605\n",
      "FP: 4\n",
      "FN: 242\n",
      "TP: 4\n",
      "Accuracy: 93.6186770428\n",
      "Sensitivity: 1.62601626016\n",
      "Specificity: 99.889165974\n"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "clf= RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "#train the model\n",
    "model= clf.fit(X_train,y_train)\n",
    "\n",
    "#test the model and find model's performance metric\n",
    "predicted= model.predict(X_test)\n",
    "\n",
    "# calculating specifity and sensitivity\n",
    "# 0  := Negative(FraudNotFound)\n",
    "# 1 := Positive (FraudFound)\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"TN:\",TN)\n",
    "print(\"FP:\",FP)\n",
    "print(\"FN:\",FN)\n",
    "print(\"TP:\",TP)\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28992, 97) (28992,)\n",
      "(21744, 97) (7248, 97)\n"
     ]
    }
   ],
   "source": [
    "#With SMOTE \n",
    "\n",
    "#apply the Smote\n",
    "sm= SMOTE()\n",
    "features,labels= sm.fit_sample(car_features,car_label)\n",
    "print(features.shape,labels.shape)\n",
    "\n",
    "#split the smote generated data into the train and test set\n",
    "X_train,X_test,y_train,y_test= train_test_split(features,labels,random_state=3,test_size=0.25)\n",
    "print(X_train.shape,X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3567   56]\n",
      " [ 149 3476]]\n",
      "TN: 3567\n",
      "FP: 56\n",
      "FN: 149\n",
      "TP: 3476\n",
      "Accuracy: 97.1716335541\n",
      "Sensitivity: 95.8896551724\n",
      "Specificity: 98.4543196246\n"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "clf= RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "#train the model\n",
    "model= clf.fit(X_train,y_train)\n",
    "\n",
    "#test the model and find model's performance metric\n",
    "predicted= model.predict(X_test)\n",
    "\n",
    "# calculating specifity and sensitivity\n",
    "# 0  := Negative(FraudNotFound)\n",
    "# 1 := Positive (FraudFound)\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"TN:\",TN)\n",
    "print(\"FP:\",FP)\n",
    "print(\"FN:\",FN)\n",
    "print(\"TP:\",TP)\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28992, 97) (28992,)\n",
      "(21744, 97) (7248, 97)\n"
     ]
    }
   ],
   "source": [
    "#apply the Smote\n",
    "sm= SMOTE()\n",
    "features,labels= sm.fit_sample(car_features,car_label)\n",
    "print(features.shape,labels.shape)\n",
    "\n",
    "#split the smote generated data into the train and test set\n",
    "X_train,X_test,y_train,y_test= train_test_split(features,labels,random_state=3,test_size=0.25)\n",
    "print(X_train.shape,X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of data in smote generated data:  28992\n",
      "Total fraud in smote generated data:  14496\n",
      "Total Non-fraud in smote generated data:  14496\n"
     ]
    }
   ],
   "source": [
    "#find the total number of the fraudulent claims in the smote generated data\n",
    "#find the all the fradulent claims in the dataset\n",
    "total_fraud= 0\n",
    "total_Nonfraud= 0\n",
    "print(\"Total no of data in smote generated data: \",labels.shape[0])\n",
    "for i in range(labels.shape[0]):\n",
    "    if labels[i]==1:\n",
    "        total_fraud += 1\n",
    "    else:\n",
    "        total_Nonfraud += 1\n",
    "print(\"Total fraud in smote generated data: \", total_fraud)\n",
    "print(\"Total Non-fraud in smote generated data: \", total_Nonfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X_test  and y_test ((7248, 97), (7248,))\n",
      "Total number of fraudulent claims in original data: 923\n"
     ]
    }
   ],
   "source": [
    "#testing only on the original test data\n",
    "from numpy import linalg as LA\n",
    "\n",
    "#print the original size of the smote generated test set\n",
    "print( \"Original X_test  and y_test\", (X_test.shape, y_test.shape))\n",
    "\n",
    "#find the all the fradulent claims in the dataset\n",
    "indexOFfraudulent= []\n",
    "columnfeatures= list(car_features.columns.values)\n",
    "fraudulentClaims= pd.DataFrame(columns=columnfeatures)\n",
    "j= 0\n",
    "for i in range(car_label.shape[0]):\n",
    "    if car_label[i]==1:\n",
    "        fraudulentClaims.loc[j]= car_features.loc[i]\n",
    "        j += 1\n",
    "print(\"Total number of fraudulent claims in original data:\",fraudulentClaims.shape[0])\n",
    "#print(y_test[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#remove the smote generated sample from the test set.\n",
    "k= 0\n",
    "index= []\n",
    "\n",
    "\n",
    "#make empty dataframes for storing the new test data\n",
    "new_X_test= pd.DataFrame(columns=columnfeatures)\n",
    "new_y_test= pd.DataFrame(columns=['label'])\n",
    "\n",
    "#convert numpy array to pd.DataFrame\n",
    "X_test= pd.DataFrame(X_test)\n",
    "\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "#for i in range(1000):\n",
    "    element= X_test.loc[i]\n",
    "    if (int(y_test[i])==1):\n",
    "        #print(\"Inside condition y_test== 1, y_test[i] is:\",y_test[i])\n",
    "        for j in range(fraudulentClaims.shape[0]):\n",
    "            data = pd.Series(element).values\n",
    "            fraudClaims= fraudulentClaims.loc[j]\n",
    "            fraudClaims= pd.Series(fraudClaims).values\n",
    "            euclidean_distance= LA.norm(data-fraudClaims,2)   #calculate the euclidean distance\n",
    "\n",
    "            if (euclidean_distance == 0):\n",
    "                index.append(i)\n",
    "                new_X_test.loc[k]= [element[elm] for elm in range(element.shape[0])]\n",
    "                #print(\"After euclidean distance==0, y_test[i] is:\",y_test[i])\n",
    "                new_y_test.loc[k]= y_test[i]\n",
    "                break\n",
    "    else:\n",
    "        new_X_test.loc[k]= [element[elm] for elm in range(element.shape[0])]\n",
    "        #print(\"Else condition, y_test[i]:\",y_test[i])\n",
    "        new_y_test.loc[k]= y_test[i]\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New X_test and y_test shape: (3855, 97) (3855, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"New X_test and y_test shape:\",new_X_test.shape,new_y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3855, 97)\n",
      "(3855, 1)\n",
      "Total Number of fraud in modified test set: 232\n"
     ]
    }
   ],
   "source": [
    "#find the original test set from smote generated dataset\n",
    "print(new_X_test.shape)\n",
    "print(new_y_test.shape)\n",
    "\n",
    "#change the dataframe into numpy array\n",
    "mod_X_test= new_X_test.values\n",
    "mod_y_test= new_y_test.values\n",
    "\n",
    "fraud= 0\n",
    "for i in range(mod_y_test.shape[0]):\n",
    "    if(mod_y_test[i]==1):\n",
    "        fraud += 1\n",
    "print(\"Total Number of fraud in modified test set:\",fraud)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3566   57]\n",
      " [ 140   92]]\n",
      "TN: 3566\n",
      "FP: 57\n",
      "FN: 140\n",
      "TP: 92\n",
      "Accuracy: 94.8897535668\n",
      "Sensitivity: 39.6551724138\n",
      "Specificity: 98.4267181893\n"
     ]
    }
   ],
   "source": [
    "#train the model with new modified test set\n",
    "#build the model\n",
    "clf= RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "#train the model\n",
    "model= clf.fit(X_train,y_train)\n",
    "\n",
    "#test the model and find model's performance metric\n",
    "#predicted= model.predict(mod_X_test)\n",
    "predicted= model.predict(mod_X_test)\n",
    "\n",
    "# calculating specifity and sensitivity\n",
    "# 0  := Negative(FraudNotFound)\n",
    "# 1 := Positive (FraudFound)\n",
    "#cm = confusion_matrix(mod_y_test,predicted)\n",
    "cm = confusion_matrix(mod_y_test,predicted)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"TN:\",TN)\n",
    "print(\"FP:\",FP)\n",
    "print(\"FN:\",FN)\n",
    "print(\"TP:\",TP)\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

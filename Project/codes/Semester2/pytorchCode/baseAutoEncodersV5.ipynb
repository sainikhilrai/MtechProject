{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15420 entries, 0 to 15419\n",
      "Data columns (total 33 columns):\n",
      "Month                   15420 non-null object\n",
      "WeekOfMonth             15420 non-null int64\n",
      "DayOfWeek               15420 non-null object\n",
      "Make                    15420 non-null object\n",
      "AccidentArea            15420 non-null object\n",
      "DayOfWeekClaimed        15420 non-null object\n",
      "MonthClaimed            15420 non-null object\n",
      "WeekOfMonthClaimed      15420 non-null int64\n",
      "Sex                     15420 non-null object\n",
      "MaritalStatus           15420 non-null object\n",
      "Age                     15420 non-null int64\n",
      "Fault                   15420 non-null object\n",
      "PolicyType              15420 non-null object\n",
      "VehicleCategory         15420 non-null object\n",
      "VehiclePrice            15420 non-null object\n",
      "FraudFound              15420 non-null object\n",
      "PolicyNumber            15420 non-null int64\n",
      "RepNumber               15420 non-null int64\n",
      "Deductible              15420 non-null int64\n",
      "DriverRating            15420 non-null int64\n",
      "Days:Policy-Accident    15420 non-null object\n",
      "Days:Policy-Claim       15420 non-null object\n",
      "PastNumberOfClaims      15420 non-null object\n",
      "AgeOfVehicle            15420 non-null object\n",
      "AgeOfPolicyHolder       15420 non-null object\n",
      "PoliceReportFiled       15420 non-null object\n",
      "WitnessPresent          15420 non-null object\n",
      "AgentType               15420 non-null object\n",
      "NumberOfSuppliments     15420 non-null object\n",
      "AddressChange-Claim     15420 non-null object\n",
      "NumberOfCars            15420 non-null object\n",
      "Year                    15420 non-null int64\n",
      "BasePolicy              15420 non-null object\n",
      "dtypes: int64(8), object(25)\n",
      "memory usage: 3.9+ MB\n",
      "index:  1516\n",
      "\n",
      "index: 1516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda35/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "import preprocessingWithMissingvalues\n",
    "\n",
    "carDf= preprocessingWithMissingvalues.preprocess('../ann/cardata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the lable from the dataset\n",
    "carDf.head()\n",
    "carLable= carDf['Lable']\n",
    "carDf.drop(['Lable'],inplace=True,axis=1) #drop the lable;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "carDateNormalized= carDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the data into fraudulent and non-fraudulent data\n",
    "columnlable= list(carDateNormalized.columns.values)\n",
    "\n",
    "#create the dataframe for fraudulent and non-fraudulent data\n",
    "nonFraudulent= pd.DataFrame(columns=columnlable)\n",
    "nonFraudulentLable= pd.DataFrame(columns=['lable'])\n",
    "\n",
    "fraudulent= pd.DataFrame(columns=columnlable)\n",
    "fraudulentLable= pd.DataFrame(columns=['lable'])\n",
    "\n",
    "\n",
    "j= 0\n",
    "k= 0\n",
    "for i in range(carDateNormalized.shape[0]):\n",
    "    if(carLable[i]==0):\n",
    "        nonFraudulent.loc[j]= carDateNormalized.loc[i]\n",
    "        nonFraudulentLable.loc[j]= 0.0\n",
    "        j += 1\n",
    "    else:\n",
    "        fraudulent.loc[k]= carDateNormalized.loc[i]\n",
    "        fraudulentLable.loc[i]= 1.0\n",
    "        k += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14496, 97)\n",
      "(923, 97)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make_Accura</th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Chevrolet</th>\n",
       "      <th>Make_Dodge</th>\n",
       "      <th>Make_Ferrari</th>\n",
       "      <th>Make_Ford</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Jaguar</th>\n",
       "      <th>Make_Lexus</th>\n",
       "      <th>Make_Mazda</th>\n",
       "      <th>...</th>\n",
       "      <th>AddressChange-Claim_under 6 months</th>\n",
       "      <th>NumberOfCars_1 vehicle</th>\n",
       "      <th>NumberOfCars_2 vehicles</th>\n",
       "      <th>NumberOfCars_3 to 4</th>\n",
       "      <th>NumberOfCars_5 to 8</th>\n",
       "      <th>NumberOfCars_more than 8</th>\n",
       "      <th>RepNo</th>\n",
       "      <th>Deductible</th>\n",
       "      <th>DriverRating</th>\n",
       "      <th>DaysDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.089744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.107692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Make_Accura  Make_BMW  Make_Chevrolet  Make_Dodge  Make_Ferrari  Make_Ford  \\\n",
       "0          0.0       0.0             0.0         0.0           0.0        0.0   \n",
       "1          0.0       0.0             0.0         0.0           0.0        0.0   \n",
       "2          0.0       0.0             0.0         0.0           0.0        0.0   \n",
       "3          0.0       0.0             0.0         0.0           0.0        0.0   \n",
       "4          0.0       0.0             0.0         0.0           0.0        0.0   \n",
       "\n",
       "   Make_Honda  Make_Jaguar  Make_Lexus  Make_Mazda    ...     \\\n",
       "0         1.0          0.0         0.0         0.0    ...      \n",
       "1         1.0          0.0         0.0         0.0    ...      \n",
       "2         1.0          0.0         0.0         0.0    ...      \n",
       "3         0.0          0.0         0.0         0.0    ...      \n",
       "4         1.0          0.0         0.0         0.0    ...      \n",
       "\n",
       "   AddressChange-Claim_under 6 months  NumberOfCars_1 vehicle  \\\n",
       "0                                 0.0                     0.0   \n",
       "1                                 0.0                     1.0   \n",
       "2                                 0.0                     1.0   \n",
       "3                                 0.0                     1.0   \n",
       "4                                 0.0                     1.0   \n",
       "\n",
       "   NumberOfCars_2 vehicles  NumberOfCars_3 to 4  NumberOfCars_5 to 8  \\\n",
       "0                      0.0                  1.0                  0.0   \n",
       "1                      0.0                  0.0                  0.0   \n",
       "2                      0.0                  0.0                  0.0   \n",
       "3                      0.0                  0.0                  0.0   \n",
       "4                      0.0                  0.0                  0.0   \n",
       "\n",
       "   NumberOfCars_more than 8     RepNo  Deductible  DriverRating  DaysDiff  \n",
       "0                       0.0  0.733333        0.00      0.000000  0.071795  \n",
       "1                       0.0  0.933333        0.25      1.000000  0.069231  \n",
       "2                       0.0  0.400000        0.25      0.666667  0.089744  \n",
       "3                       0.0  0.200000        0.25      0.333333  0.107692  \n",
       "4                       0.0  0.133333        0.25      0.000000  0.094872  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(nonFraudulent.shape)\n",
    "print(fraudulent.shape)\n",
    "nonFraudulent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataframe\n",
    "nonFraudulentLable= pd.DataFrame(nonFraudulentLable)\n",
    "fraudulentLable= pd.DataFrame(fraudulentLable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the preprocessed data\n",
    "nonFraudulent.to_csv(\"nonFraudulentFeatures.csv\",index=False,sep=\",\",header=columnlable)\n",
    "fraudulent.to_csv(\"fraudulentFeatures.csv\",sep=\",\",index=False,header=columnlable)\n",
    "fraudulentLable.to_csv(\"fraudulentLable.csv\",sep=\",\",index=False,header='Lable')\n",
    "nonFraudulentLable.to_csv(\"nonFraudulentLable.csv\",sep=\",\",index=False,header='Lable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lable\n",
       "28    1.0\n",
       "52    1.0\n",
       "53    1.0\n",
       "94    1.0\n",
       "96    1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nonFraudulent.head()\n",
    "fraudulentLable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-Fraud: 14496\n",
      "Fraud: 923\n"
     ]
    }
   ],
   "source": [
    "#Note that for the train and test split, the lables and data have to be in numpy\n",
    "nonFraudulentCarfeatures= nonFraudulent.values\n",
    "nonFraudulentLable= nonFraudulentLable.values\n",
    "\n",
    "fraudulentCarfeatures= fraudulent.values\n",
    "fraudulentLable= fraudulentLable.values\n",
    "\n",
    "print('non-Fraud: %d' %(nonFraudulentCarfeatures.shape[0]))\n",
    "print('Fraud: %d' %(fraudulentCarfeatures.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonFraudxtrain: <class 'numpy.ndarray'>\n",
      "(3624, 97)\n",
      "fraudxtrain: <class 'numpy.ndarray'>\n",
      "(231, 97)\n"
     ]
    }
   ],
   "source": [
    "#divide the nonFraudulent into test and train\n",
    "nonFraudX_train,nonFraudX_test,nonFraudY_train,nonFraudY_test = train_test_split(nonFraudulentCarfeatures,nonFraudulentLable,random_state=3,test_size=0.25)\n",
    "print('nonFraudxtrain:',type(nonFraudX_train))\n",
    "print(nonFraudX_test.shape)\n",
    "\n",
    "#divide the fraudulent into test and train\n",
    "fraudX_train,fraudX_test,fraudY_train,fraudY_test = train_test_split(fraudulentCarfeatures, fraudulentLable,random_state=3,test_size=0.25)\n",
    "print('fraudxtrain:',type(fraudX_train))\n",
    "print(fraudX_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the class Dataset which returns the data and labels\n",
    "from torch.utils.data.dataset import Dataset, TensorDataset\n",
    "class myDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,features,lables,transform= None):\n",
    "        dataTensor= []\n",
    "        lableTensor= []\n",
    "        dataSize= features.shape[0]\n",
    "        \n",
    "        for data in range(dataSize):\n",
    "            feature= features[data,:]\n",
    "            #feature= torch.from_numpy(feature).float()\n",
    "            feature= torch.Tensor(feature)\n",
    "            dataTensor.append(feature)\n",
    "            \n",
    "            lable= np.asanyarray(lables[data])\n",
    "            lable= torch.from_numpy(lable).float()\n",
    "           \n",
    "            #lable= torch.Tensor(lable)\n",
    "            #print(\"lable:\",lable)\n",
    "            #assert(False)\n",
    "           \n",
    "            lableTensor.append(lable)\n",
    "        \n",
    "        #put everything in features and lables\n",
    "        self.features= dataTensor\n",
    "        self.lables= lableTensor\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        feature= self.features[index]\n",
    "        lable= self.lables[index]\n",
    "        #print(\"get_item feature:\",feature)\n",
    "        #print(\"get_item lable:\",lable)\n",
    "        return feature,lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the  nonfraudulent dataset for train and test loader\n",
    "myNonFraudulentTrainDataset= myDataset(nonFraudX_train,nonFraudY_train)\n",
    "myNonFraudulentTestDataset= myDataset(nonFraudX_test,nonFraudY_test)\n",
    "\n",
    "#make the fraudulent dataset for train and test loader\n",
    "myFraudulentTrainDataset= myDataset(fraudX_train,fraudY_train)\n",
    "myFraudulentTestDataset= myDataset(fraudX_test,fraudY_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "        0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.2500, 0.0000, 0.0641])\n",
      "lable: tensor([0.])\n",
      "torch.Size([97])\n"
     ]
    }
   ],
   "source": [
    "feature,lable= myNonFraudulentTrainDataset.__getitem__(0)\n",
    "print(\"feature:\",feature)\n",
    "print(\"lable:\",lable)\n",
    "print(feature.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make the trainloader and test loader for nonfraudulent dataset.\n",
    "nonFraudulentTrainLoader= torch.utils.data.DataLoader(myNonFraudulentTrainDataset,batch_size=1,shuffle=True,num_workers=0)\n",
    "nonFraudulentTestLoader= torch.utils.data.DataLoader(myNonFraudulentTestDataset,batch_size=1,shuffle=True,num_workers=0)\n",
    "\n",
    "fraudulentTrainLoader= torch.utils.data.DataLoader(myFraudulentTrainDataset,batch_size=1,shuffle=True,num_workers=0)\n",
    "fraudulentTestLoader= torch.utils.data.DataLoader(myFraudulentTestDataset,batch_size=1,shuffle=True,num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network architecture for the base autoencoders\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder,self).__init__()\n",
    "        self.encoder= nn.Sequential(\n",
    "            nn.Linear(97,70),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(70,60),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(60,45),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(45,20),nn.LeakyReLU(True),nn.Linear(20,10))\n",
    "        \n",
    "        self.decoder= nn.Sequential(\n",
    "            nn.Linear(10,20),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(20,45),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(45,60),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(60,70),nn.LeakyReLU(True),nn.Linear(70,97),nn.ReLU())\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x= self.encoder(x)\n",
    "        x= self.decoder(x)\n",
    "        return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= autoencoder()\n",
    "criterion= nn.MSELoss()\n",
    "optimizer= torch.optim.SGD(model.parameters(), lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-05e0c5e2bb42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minputs1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlables1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlable1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlables1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# =====================forward====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lables' is not defined"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "for epoch in range(50):\n",
    "    running_loss= 0.0\n",
    "    for i, (feature1,lable1) in enumerate(nonFraudulentTrainLoader):\n",
    "        \n",
    "        #gets the inputs\n",
    "        inputs1= torch.tensor(feature1)\n",
    "        lables1= torch.tensor(lable1)\n",
    "        lables1= lables.type(torch.LongTensor)\n",
    "        \n",
    "        # =====================forward====================\n",
    "        output1 = model(inputs1)\n",
    "        loss1 = criterion(output1,inputs1)\n",
    "        \n",
    "         # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # =======print the statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #print(\"i: \",i)\n",
    "    #if i%100 == 0:              #print every 2000 mini-batches\n",
    "    \n",
    "    print('[%d] loss: %.3f' %\n",
    "              (epoch + 1,  running_loss /nonFraudX_train.shape[0]))\n",
    "      #running_loss = 0.0\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #test the model\n",
    "def modelTest(Loader):\n",
    "    lossList= []\n",
    "    trueLable1= []\n",
    "    for i,(feature1,lable1) in enumerate(Loader):\n",
    "        inputs1= torch.tensor(feature1)\n",
    "        output1= model(inputs1)\n",
    "        loss1= criterion(output1,inputs1)\n",
    "        trueLable1.append(lable)\n",
    "        lossList.append(loss.item())\n",
    "        \n",
    "        if(i!=10):\n",
    "            print(\"input1:\",inputs1)\n",
    "            print(\"output1:\",output1)\n",
    "            print(\"loss1:\",loss1)\n",
    "            print(\"lable:\",lable1)\n",
    "        else:\n",
    "            assert(False)\n",
    "        \n",
    "    return lossList,trueLable1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model\n",
    "lossList,trueLable1= modelTest(nonFraudulentTestLoader)\n",
    "len(lossList)\n",
    "lossList[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trueLable1)\n",
    "int(trueLable1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network architecture for the base autoencoders\n",
    "class autoencoder2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder2,self).__init__()\n",
    "        self.encoder2= nn.Sequential(\n",
    "            nn.Linear(97,75),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(75,50),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(50,25),nn.LeakyReLU(True),nn.Linear(25,10))\n",
    "       \n",
    "        self.decoder2= nn.Sequential(\n",
    "            nn.Linear(10,25),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(25,50),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(50,75),nn.LeakyReLU(True),nn.Linear(75,97),nn.ReLU())\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x= self.encoder2(x)\n",
    "        x= self.decoder2(x)\n",
    "        return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2= autoencoder2()\n",
    "criterion2= nn.MSELoss()\n",
    "optimizer2= torch.optim.SGD(model2.parameters(), lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model2\n",
    "for epoch in range(100):\n",
    "    running_loss2= 0.0\n",
    "    for i, (feature2,lable2) in enumerate(fraudulentTestLoader):\n",
    "        \n",
    "        #gets the inputs\n",
    "        inputs2= torch.tensor(feature2)\n",
    "        lables2= torch.tensor(lable2)\n",
    "        lables2= lables2.type(torch.LongTensor)\n",
    "       \n",
    "        # =====================forward====================\n",
    "        output2= model2(inputs2)\n",
    "        loss2= criterion2(output2,inputs2)\n",
    "        \n",
    "        # ===================backward====================\n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        # =======print the statistics\n",
    "        running_loss2 += loss2.item()\n",
    "        \n",
    "        #print(\"i: \",i)\n",
    "    #if i%100 == 0:              #print every 2000 mini-batches\n",
    "    \n",
    "    print('[%d] loss: %.3f' %\n",
    "              (epoch + 1,  running_loss2 / fraudulentCarfeatures.shape[0]))\n",
    "      #running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTest2(Loader2):\n",
    "    lossList2= []\n",
    "    trueLable1= []\n",
    "    for i,(feature2,lable2) in enumerate(Loader2):\n",
    "        inputs2= torch.tensor(feature2)\n",
    "        output2= model2(inputs2)\n",
    "        loss2= criterion(output2,inputs2)\n",
    "        trueLable1.append(lable2)\n",
    "        \n",
    "        lossList2.append(loss2.item()) #put the loss\n",
    "        if(i!=10):\n",
    "            print(\"input2:\",inputs2)\n",
    "            print(\"output2:\",output2)\n",
    "            print(\"loss2:\",loss2)\n",
    "            print(\"lable2:\",lable2)\n",
    "        else:\n",
    "            assert(False)\n",
    "            \n",
    "    return lossList2,trueLable1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossList2,trueLable1= modelTest2(nonFraudulentTestLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loss1:\",lossList[1])\n",
    "print(\"loss2:\",lossList2[1])\n",
    "len(trueLable1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedLable1=[]\n",
    "for k in range(len(lossList)):\n",
    "    if(lossList[k]<lossList2[k]):\n",
    "        predictedLable1.append(0)\n",
    "    else:\n",
    "        predictedLable1.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class1= predictedLable1.count(1)\n",
    "class0= predictedLable1.count(0)\n",
    "print('%d %d' %(class1,class0))\n",
    "len(trueLable1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model1 with another type of data\n",
    "lossList3,trueLable2= modelTest(fraudulentTestLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model2 with another type of data\n",
    "lossList4,trueLable2= modelTest2(fraudulentTestLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedLable2=[]\n",
    "for k in range(len(lossList3)):\n",
    "    if(lossList3[k]<lossList4[k]):\n",
    "        predictedLable2.append(0)\n",
    "    else:\n",
    "        predictedLable2.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1= predictedLable2.count(1)\n",
    "class0= predictedLable2.count(0)\n",
    "print('%d %d' %(class1,class0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLength1= len(trueLable1)\n",
    "TP=FP=FN=TN= 0\n",
    "for i in range(totalLength1):\n",
    "    if(int(trueLable1[i])==1 and predictedLable1[i]==1):\n",
    "        TP += 1\n",
    "    elif(int(trueLable1[i])==1 and predictedLable1[i]==0):\n",
    "        FN += 1\n",
    "    elif(int(trueLable1[i])==0 and predictedLable1[i]==0):\n",
    "        TN += 1\n",
    "    elif(int(trueLable1[i])==0 and predictedLable1[i]==1):\n",
    "        FP += 1\n",
    "\n",
    "totalLength2= len(trueLable2)\n",
    "for i in range(totalLength2):\n",
    "    if(int(trueLable2[i])==1 and predictedLable2[i]==1):\n",
    "        TP += 1\n",
    "    elif(int(trueLable2[i])==1 and predictedLable2[i]==0):\n",
    "        FN += 1\n",
    "    elif(int(trueLable2[i])==0 and predictedLable2[i]==0):\n",
    "        TN += 1\n",
    "    elif(int(trueLable2[i])==0 and predictedLable2[i]==1):\n",
    "        FP += 1\n",
    "        \n",
    "print(\"\\nResult \")\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)\n",
    "print(\"\\n\")\n",
    "print(\"\\nTP:\",TP)\n",
    "print(\"\\nFN:\",FN)\n",
    "print(\"\\nFP:\",FP)\n",
    "print(\"\\nTN:\",TN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

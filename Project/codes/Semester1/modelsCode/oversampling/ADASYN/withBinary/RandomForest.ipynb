{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.5/site-packages/sklearn/utils/fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read the data into dataframe\n",
    "car_df = pd.read_csv('newCardata.csv')\n",
    "car_features = pd.read_csv('finalDataPreprocessBinary.csv')\n",
    "car_label = car_df['FraudFound']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15419,)\n"
     ]
    }
   ],
   "source": [
    "#change the label of the data\n",
    "labelNo = LabelEncoder()\n",
    "car_df['FraudFound'] = labelNo.fit_transform(car_df['FraudFound'].astype('str'))\n",
    "car_label = car_df['FraudFound']\n",
    "print(car_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15419, 52) (15419,)\n",
      "xtrain: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#split the data into train and test\n",
    "print(car_features.shape,car_label.shape)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(car_features,car_label,random_state=3,test_size=0.25)\n",
    "print('xtrain:',type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf='deprecated', min_samples_split=2,\n",
       "            min_weight_fraction_leaf='deprecated', n_estimators=100,\n",
       "            n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model object\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier:\n",
      "<class 'numpy.ndarray'> (3855,) [0 0 0 ..., 0 0 0]\n",
      "Accuracy is  93.67\n"
     ]
    }
   ],
   "source": [
    "print('Random forest classifier:')\n",
    "predicted = model.predict(X_test)\n",
    "print(type(predicted),predicted.shape,predicted)\n",
    "print('Accuracy is ',round(accuracy_score(y_test,model.predict(X_test)) * 100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3606    3]\n",
      " [ 241    5]]\n",
      "TN: 3606\n",
      "FP: 3\n",
      "FN: 241\n",
      "TP: 5\n",
      "Accuracy: 93.6705577173\n",
      "Sensitivity: 2.0325203252\n",
      "Specificity: 99.9168744805\n"
     ]
    }
   ],
   "source": [
    "# calculating specifity and sensitivity\n",
    "# 0  := Negative\n",
    "# 1 := Positive\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print(\"TN:\",TN)\n",
    "print(\"FP:\",FP)\n",
    "print(\"FN:\",FN)\n",
    "print(\"TP:\",TP)\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'>\n",
      "3855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#converting pandas.core.series.Series to numpy.ndarray\n",
    "print(type(y_test),type(predicted))\n",
    "ytest = pd.Series(y_test).values\n",
    "print((ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of fraud cases: 246\n",
      "No of fauld cases predicted by model: 8\n",
      "No of fraud correctly predicted  as fault: 5\n"
     ]
    }
   ],
   "source": [
    "#find the index where both are 1.\n",
    "count = 0\n",
    "fault = 0\n",
    "predictedfault = 0\n",
    "for i in range(predicted.shape[0]):\n",
    "    if((predicted[i] == 1) and (ytest[i] == 1)):\n",
    "        count += 1\n",
    "    if(ytest[i] == 1):\n",
    "        fault += 1\n",
    "    if(predicted[i]==1):\n",
    "        predictedfault += 1\n",
    "print(\"No of fraud cases:\",fault)\n",
    "print(\"No of fauld cases predicted by model:\",predictedfault)\n",
    "print(\"No of fraud correctly predicted  as fault:\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier:\n"
     ]
    }
   ],
   "source": [
    "# CROSS_VALIDATION: 10-FOLD CROSS VALIDATION\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "print('Random forest classifier:')\n",
    "\n",
    "sm = ADASYN(random_state=100,n_neighbors=5,n_jobs=1)\n",
    "features,labels = sm.fit_sample(car_features,car_label)\n",
    "\n",
    "#convert np.array to dataframe \n",
    "df_features = pd.DataFrame(features)\n",
    "df_lables = pd.DataFrame(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971890211845\n",
      "0.841742771812\n",
      "0.707948639019\n",
      "0.758572906705\n"
     ]
    }
   ],
   "source": [
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=10)\n",
    "model=RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "results = model_selection.cross_validate(estimator=model,X=features,y=labels,cv=kfold,scoring=scoring)\n",
    "#add the both the labels and features\n",
    "df_features['FraudFound']= df_lables\n",
    "\n",
    "#shuffle the featrues\n",
    "new_combine_features = df_features.set_index(np.random.permutation(df_features.index))\n",
    "\n",
    "\n",
    "new_label = new_combine_features['FraudFound']\n",
    "\n",
    "#drop the FraudFound attribute\n",
    "new_combine_features.drop(['FraudFound'],inplace=True,axis=1)\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=10)\n",
    "model=RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "results = model_selection.cross_validate(estimator=model,X=new_combine_features,y=new_label,cv=kfold,scoring=scoring)\n",
    "\n",
    "print(np.mean(results['test_accuracy']))\n",
    "print(np.mean(results['test_precision']))\n",
    "print(np.mean(results['test_recall']))\n",
    "print(np.mean(results['test_f1_score']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

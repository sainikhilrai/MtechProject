{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import math\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15419, 97)\n"
     ]
    }
   ],
   "source": [
    "#Read the data into dataframe\n",
    "car_df = pd.read_csv('newCardata.csv')\n",
    "car_features = pd.read_csv('finalDataPreprocess.csv')\n",
    "\n",
    "#encode the label as 1's or 0's\n",
    "label_Number = LabelEncoder()\n",
    "car_df['FraudFound'] = label_Number.fit_transform(car_df['FraudFound'].astype('str'))\n",
    "car_label = car_df['FraudFound']\n",
    "print(car_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11564, 97) (3855, 97)\n"
     ]
    }
   ],
   "source": [
    "#divide the data into train and test set\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(car_features,car_label,random_state=3,test_size=0.25)\n",
    "print(X_train.shape,X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3608    1]\n",
      " [ 240    6]]\n",
      "TN: 3608\n",
      "FP: 1\n",
      "FN: 240\n",
      "TP: 6\n",
      "Accuracy: 93.7483787289\n",
      "Sensitivity: 2.43902439024\n",
      "Specificity: 99.9722914935\n"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "clf= RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "#train the model\n",
    "model= clf.fit(X_train,y_train)\n",
    "\n",
    "#test the model and find model's performance metric\n",
    "predicted= model.predict(X_test)\n",
    "\n",
    "# calculating specifity and sensitivity\n",
    "# 0  := Negative(FraudNotFound)\n",
    "# 1 := Positive (FraudFound)\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"TN:\",TN)\n",
    "print(\"FP:\",FP)\n",
    "print(\"FN:\",FN)\n",
    "print(\"TP:\",TP)\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28992, 97) (28992,)\n",
      "(20294, 97) (8698, 97)\n"
     ]
    }
   ],
   "source": [
    "#With SMOTE \n",
    "\n",
    "#apply the Smote\n",
    "sm= SMOTE()\n",
    "features,labels= sm.fit_sample(car_features,car_label)\n",
    "print(features.shape,labels.shape)\n",
    "\n",
    "#split the smote generated data into the train and test set\n",
    "X_train,X_test,y_train,y_test= train_test_split(features,labels,random_state=10,test_size=0.30)\n",
    "print(X_train.shape,X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4223   69]\n",
      " [ 171 4235]]\n",
      "TN: 4223\n",
      "FP: 69\n",
      "FN: 171\n",
      "TP: 4235\n",
      "Accuracy: 97.2407449989\n",
      "Sensitivity: 96.1189287335\n",
      "Specificity: 98.3923578751\n"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "clf= RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "#train the model\n",
    "model= clf.fit(X_train,y_train)\n",
    "\n",
    "#test the model and find model's performance metric\n",
    "predicted= model.predict(X_test)\n",
    "\n",
    "# calculating specifity and sensitivity\n",
    "# 0  := Negative(FraudNotFound)\n",
    "# 1 := Positive (FraudFound)\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"TN:\",TN)\n",
    "print(\"FP:\",FP)\n",
    "print(\"FN:\",FN)\n",
    "print(\"TP:\",TP)\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28992, 97) (28992,)\n",
      "(21744, 97) (7248, 97)\n"
     ]
    }
   ],
   "source": [
    "#apply the Smote\n",
    "sm= SMOTE()\n",
    "features,labels= sm.fit_sample(car_features,car_label)\n",
    "print(features.shape,labels.shape)\n",
    "\n",
    "#split the smote generated data into the train and test set\n",
    "X_train,X_test,y_train,y_test= train_test_split(features,labels,random_state=3,test_size=0.25)\n",
    "print(X_train.shape,X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of data in smote generated data:  28992\n",
      "Total fraud in smote generated data:  14496\n",
      "Total Non-fraud in smote generated data:  14496\n"
     ]
    }
   ],
   "source": [
    "#find the total number of the fraudulent claims in the smote generated data\n",
    "#find the all the fradulent claims in the dataset\n",
    "total_fraud= 0\n",
    "total_Nonfraud= 0\n",
    "print(\"Total no of data in smote generated data: \",labels.shape[0])\n",
    "for i in range(labels.shape[0]):\n",
    "    if labels[i]==1:\n",
    "        total_fraud += 1\n",
    "    else:\n",
    "        total_Nonfraud += 1\n",
    "print(\"Total fraud in smote generated data: \", total_fraud)\n",
    "print(\"Total Non-fraud in smote generated data: \", total_Nonfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X_test  and y_test ((7248, 97), (7248,))\n",
      "Total number of fraudulent claims in original data: 923\n"
     ]
    }
   ],
   "source": [
    "#testing only on the original test data\n",
    "from numpy import linalg as LA\n",
    "\n",
    "#print the original size of the smote generated test set\n",
    "print( \"Original X_test  and y_test\", (X_test.shape, y_test.shape))\n",
    "\n",
    "#find the all the fradulent claims in the dataset\n",
    "indexOFfraudulent= []\n",
    "columnfeatures= list(car_features.columns.values)\n",
    "fraudulentClaims= pd.DataFrame(columns=columnfeatures)\n",
    "fraudLabel= pd.DataFrame(columns=['label'])\n",
    "j= 0\n",
    "for i in range(car_label.shape[0]):\n",
    "    if car_label[i]==1:\n",
    "        fraudulentClaims.loc[j]= car_features.loc[i]\n",
    "        fraudLabel.loc[i]= 1\n",
    "        j += 1\n",
    "print(\"Total number of fraudulent claims in original data:\",fraudulentClaims.shape[0])\n",
    "#print(y_test[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d97287b37299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#for i in range(1000):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0melement\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(\"Inside condition y_test== 1, y_test[i] is:\",y_test[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#remove the smote generated sample from the test set.\n",
    "k= 0\n",
    "index= []\n",
    "\n",
    "\n",
    "#make empty dataframes for storing the new test data\n",
    "new_X_test= pd.DataFrame(columns=columnfeatures)\n",
    "new_y_test= pd.DataFrame(columns=['label'])\n",
    "\n",
    "#convert numpy array to pd.DataFrame\n",
    "X_test= pd.DataFrame(X_test)\n",
    "\n",
    "print(type(X_test))\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "#for i in range(1000):\n",
    "    element= X_test.loc[i]\n",
    "    assert(False)\n",
    "    if (int(y_test[i])==1):\n",
    "        #print(\"Inside condition y_test== 1, y_test[i] is:\",y_test[i])\n",
    "        for j in range(fraudulentClaims.shape[0]):\n",
    "            data = pd.Series(element).values\n",
    "            fraudClaims= fraudulentClaims.loc[j]\n",
    "            fraudClaims= pd.Series(fraudClaims).values\n",
    "            euclidean_distance= LA.norm(data-fraudClaims,2)   #calculate the euclidean distance\n",
    "\n",
    "            if (euclidean_distance == 0):\n",
    "                index.append(i)\n",
    "                new_X_test.loc[k]= [element[elm] for elm in range(element.shape[0])]\n",
    "                #print(\"After euclidean distance==0, y_test[i] is:\",y_test[i])\n",
    "                new_y_test.loc[k]= y_test[i]\n",
    "                break\n",
    "    else:\n",
    "        new_X_test.loc[k]= [element[elm] for elm in range(element.shape[0])]\n",
    "        #print(\"Else condition, y_test[i]:\",y_test[i])\n",
    "        new_y_test.loc[k]= y_test[i]\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New X_test and y_test shape: (3855, 97) (3855, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"New X_test and y_test shape:\",new_X_test.shape,new_y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3855, 97)\n",
      "(3855, 1)\n",
      "Total Number of fraud in modified test set: 232\n"
     ]
    }
   ],
   "source": [
    "#find the original test set from smote generated dataset\n",
    "print(new_X_test.shape)\n",
    "print(new_y_test.shape)\n",
    "\n",
    "#change the dataframe into numpy array\n",
    "mod_X_test= new_X_test.values\n",
    "mod_y_test= new_y_test.values\n",
    "\n",
    "fraud= 0\n",
    "for i in range(mod_y_test.shape[0]):\n",
    "    if(mod_y_test[i]==1):\n",
    "        fraud += 1\n",
    "print(\"Total Number of fraud in modified test set:\",fraud)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3560   63]\n",
      " [ 142   90]]\n",
      "TN: 3560\n",
      "FP: 63\n",
      "FN: 142\n",
      "TP: 90\n",
      "Accuracy: 94.682230869\n",
      "Sensitivity: 38.7931034483\n",
      "Specificity: 98.2611095777\n"
     ]
    }
   ],
   "source": [
    "#train the model with new modified test set\n",
    "#build the model\n",
    "clf= RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "#train the model\n",
    "model= clf.fit(X_train,y_train)\n",
    "\n",
    "#test the model and find model's performance metric\n",
    "#predicted= model.predict(mod_X_test)\n",
    "predicted= model.predict(mod_X_test)\n",
    "\n",
    "# calculating specifity and sensitivity\n",
    "# 0  := Negative(FraudNotFound)\n",
    "# 1 := Positive (FraudFound)\n",
    "#cm = confusion_matrix(mod_y_test,predicted)\n",
    "cm = confusion_matrix(mod_y_test,predicted)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"TN:\",TN)\n",
    "print(\"FP:\",FP)\n",
    "print(\"FN:\",FN)\n",
    "print(\"TP:\",TP)\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  0   0]\n",
      " [163 760]]\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 163\n",
      "TP: 760\n",
      "Accuracy: 82.3401950163\n",
      "Sensitivity: 82.3401950163\n",
      "Specificity: nan\n"
     ]
    }
   ],
   "source": [
    "#test on original fraudulent data\n",
    "org_test= fraudulentClaims.values\n",
    "org_label= fraudLabel.values\n",
    "predicted= model.predict(org_test)\n",
    "\n",
    "# calculating specifity and sensitivity\n",
    "# 0  := Negative(FraudNotFound)\n",
    "# 1 := Positive (FraudFound)\n",
    "#cm = confusion_matrix(mod_y_test,predicted)\n",
    "cm = confusion_matrix(org_label,predicted)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",cm)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(\"TN:\",TN)\n",
    "print(\"FP:\",FP)\n",
    "print(\"FN:\",FN)\n",
    "print(\"TP:\",TP)\n",
    "\n",
    "print(\"Accuracy:\",(TP+TN)/(TP+FP+FN+TN)*100)\n",
    "print(\"Sensitivity:\",TP/(TP+FN)*100)\n",
    "print(\"Specificity:\",TN/(TN+FP)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
